{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import theano\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 4798673)\n"
     ]
    }
   ],
   "source": [
    "path=get_file('t8.shakespeare.txt', origin=\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\")\n",
    "text=open(path)\n",
    "text=text.readlines()[253:]\n",
    "text=[t.strip() for t in text]\n",
    "text=\"\\n\".join(text).lower()\n",
    "text=re.sub(r'[^a-z\\.\\n\\: ]',\"\",text)\n",
    "text=re.sub(r'\\n+',\"\\n\",text)\n",
    "\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total chars:', 30)\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices=dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char=dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sentences and Predictions, ie.. the input output pairs. \n",
    "### For every set of 30 chars we predict 1 char."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1599548/1599548 [00:01<00:00, 1360765.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "maxlen=30\n",
    "step=3\n",
    "sentences=[]\n",
    "next_chars=[]\n",
    "y_shape=len(chars)\n",
    "batch_size=100\n",
    "for i in tqdm(range(0,(len(text)-maxlen),step)):\n",
    "    sentences.append(text[i:i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "\n",
    "trim=(len(sentences)/batch_size)*batch_size\n",
    "sentences=sentences[:trim]\n",
    "next_chars=next_chars[:trim]\n",
    "print len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Vectorize \n",
    "### chars as one hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1599500it [00:34, 45774.68it/s]\n"
     ]
    }
   ],
   "source": [
    "X=np.zeros((len(sentences), maxlen, y_shape), dtype=np.bool)\n",
    "y=np.zeros((len(sentences), y_shape), dtype=np.bool)\n",
    "\n",
    "for i, sentence in tqdm(enumerate(sentences)):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]]=1\n",
    "        y[i, char_indices[next_chars[i]]]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599500, 30, 30)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.9 s, sys: 2.16 s, total: 7.06 s\n",
      "Wall time: 4.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "theano.config.compute_test_value=\"ignore\"\n",
    "model=Sequential()\n",
    "model.add(LSTM(batch_size, input_shape=(maxlen,y_shape)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_shape))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer=RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(probs, temp):\n",
    "    #samples an index from prob array, depending on temp. This is used to get next starting index.\n",
    "    probs=np.asarray(probs).astype('float64')\n",
    "    log_like=np.log(probs)/temp #log likelihood/temp\n",
    "    exp_preds=np.exp(log_like)\n",
    "    preds=exp_preds / np.sum(exp_preds)\n",
    "    probas=np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1599500/1599500 [==============================] - 652s - loss: 1.8261   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f913b3e70d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=batch_size, nb_epoch=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather is pleasant todayrible the lord\n",
      "he wistt perperint him me.\n",
      "and the this young her sonsers and falls it grant and and the catraw of the now shall will shall be wirt this to the brother\n",
      "and know and the  such the and king be the be the shes of the can to come can that these the now the ent to you princes\n",
      "and i had the grace the cound the very in a can i ave i this that hath his pandon and have hose the thend of the so me i have the come whan the hand the ham the macks  i have on thou had so the benother the flace \n"
     ]
    }
   ],
   "source": [
    "gentext=''\n",
    "first_idx=np.random.randint(0, len(text) - maxlen - 1)\n",
    "first_line=text[firs]\n",
    "gentext+=first_line\n",
    "#print first_line, maxlen,first_line_index\n",
    "for j in range(500):\n",
    "            x=np.zeros((1, maxlen, y_shape))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]]=1.\n",
    "                \n",
    "            predic=model.predict(x, verbose=0)[0]\n",
    "            temp= np.random.random()\n",
    "            next_index=sample(predic, temp)\n",
    "            next_char=indices_char[next_index]\n",
    "            gentext+=next_char\n",
    "            sentence=sentence[1:] + next_char\n",
    "print gentext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
